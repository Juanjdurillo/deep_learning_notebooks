{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2. Learning how to see\n",
    "\n",
    "Module 1 focused on how to create a first neural network that helped in classifying inputs. In this module, we will consider that the inputs to our model are images, and a network will need to understand something out of that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "We will work in this module with the MNIST dataset. This dataset contains black-and-white images of hand-written digits and their labels (i.e., the represented digit). Each image has a single digit from 0-9 (i.e., 10 classes). \n",
    "\n",
    "In this module, we will not construct the dataset ourself out of the URL where the data is stored. Instead, we will make use of the tensorflow API, which provides a convinient way of downloading MNIST and other datasets. If you are curious about which datasets are provided have a look into the [documenation](https://www.tensorflow.org/datasets). \n",
    "\n",
    "The mnist dataset documenatation can be found [here](https://www.tensorflow.org/datasets/catalog/mnist). In that documenation, you can see that the structure of the dataset is defined by the following dictionary:\n",
    "```python\n",
    "FeaturesDict({\n",
    "    'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
    "    'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
    "})\n",
    "``` \n",
    "Let us then import the data and work with it. The library entrypoint for loading a dataset is `tensorflow_datasets.load` which will allow us to download datasets for both training and testing. This latter will help us validate how the network performs on data that it has not seen during the training phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "mnist, info = tfds.load('mnist',data_dir='mnist_data',download=True,shuffle_files=True,with_info=True, as_supervised=True)\n",
    "ds_train = mnist['train']\n",
    "ds_test  = mnist['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice property of `tf.Datasets` is that it can be use as the source for your input data, it allows to apply transformations to preprocess the data as well as easily iterating over the dataset using batches, and visualizing a sample of the dataset in case this contains images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(ds_train,info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how easy is to indicate the dataset that we want to shuffle the data, use batches of 32 elements and let tensorflow decide the best parameters for prefetching data into memory according to our hardware configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test  = ds_test.shuffle(1024).batch(1).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data\n",
    "So far our dataset is composed of black-and-white images whose pixels contain values beetween 0 (black) and 255 (white). These are discrete values which might pose in principle some difficulties for an optimization algorithm. Let's normalise these values to the [0,1] interval and conver these to floats. We will do this by defining a function that will take care of doing the normalisation, and applying that function to the dataset by using its map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(image, label):\n",
    "    return tf.cast(image,tf.float32) / 255., tf.one_hot(label,depth=10)\n",
    "\n",
    "ds_train = ds_train.map(normalise,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test  = ds_test.map(normalise,num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Now is your turn. Using the Module 1 notebook, create a neural network model for recognizing the digits in the images provided in the mnist dataset. This neural network is going to be plain simple and be defined only by:\n",
    "- The input layer\n",
    "- A hidden layer of 128 neurons and `relu` activation function\n",
    "- An output layer whose size you should know from the dataset\n",
    "A caveat in this case is that the inputs in the dataset are not vectors, but matrices of (28, 28). You will need to conver this into a vector as first layer in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, )),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your have built your model, train it with the following piece of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify how our trained model performs on the testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in ds_test.take(2):\n",
    "    pred = model.predict(image)\n",
    "    print(tf.argmax(pred, axis=1))\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more complex dataset\n",
    "You will be using the Sign Language MNIST dataset, which contains 28x28 images of hands depicting the 26 letters of the english alphabet. Let's download this dataset first. The data is stored as cvs files with the label being the first element of every column and the rest of columns denoting the 28x28 pixesl of the image. We will download these files and write a parser function that read these files and return the data in form of numpy arrays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://drive.google.com/uc?id=1z0DkA9BytlLxO1C0BAWzknLyQmZAp0HR --output-document train.cvs\n",
    "!wget https://drive.google.com/uc?id=1z1BIj4qmri59GWBG4ivMNFtpZ4AXIbzg --output-document test.cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def parse_data_from_input(filename):\n",
    "  with open(filename) as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    #ignore first row\n",
    "    next(csv_reader)\n",
    "    for line in csv_reader:\n",
    "      labels.append(line[0])\n",
    "      images.append(line[1:])\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    labels = labels.astype(np.float64)\n",
    "    images = np.reshape(images,(-1,28,28))\n",
    "    images = images.astype(np.float64)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "training_images, training_labels = parse_data_from_input(\"train.cvs\")\n",
    "validation_images, validation_labels = parse_data_from_input(\"test.cvs\")\n",
    "print(training_images.dtype)\n",
    "\n",
    "print(f\"Training images has shape: {training_images.shape}\")\n",
    "print(f\"Training labels has shape: {training_labels.shape}\")\n",
    "print(f\"Validation images has shape: {validation_images.shape}\")\n",
    "print(f\"Validation labels has shape: {validation_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following piece of code to get an idea of how the dataset images look like. Obviously, we could see that it is probably more challenging to classify these images than the mnist digits. Notice that in this case we need to use the matplotlib library for plotting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "def plot_categories(training_images, training_labels):\n",
    "  fig, axes = plt.subplots(1, 10, figsize=(16, 15))\n",
    "  axes = axes.flatten()\n",
    "  letters = list(string.ascii_lowercase)\n",
    "\n",
    "  for k in range(10):\n",
    "    img = training_images[k]\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = array_to_img(img)\n",
    "    ax = axes[k]\n",
    "    ax.imshow(img, cmap=\"Greys_r\")\n",
    "    ax.set_title(f\"{letters[int(training_labels[k])]}\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "plot_categories(training_images, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we will need to feed images into a model, after normalising them. For the sake of simplicity, we will create keras generators for deadling with the train and tests datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
    "  training_images   = np.expand_dims(training_images,3)\n",
    "  validation_images = np.expand_dims(validation_images,3)\n",
    "\n",
    "  training_labels = tf.keras.utils.to_categorical(training_labels,26)\n",
    "  train_datagen   = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "  train_generator = train_datagen.flow(x=training_images,\n",
    "                                       y=training_labels,\n",
    "                                       batch_size=32) \n",
    "  \n",
    "  validation_labels  = tf.keras.utils.to_categorical(validation_labels,26)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "  validation_generator = validation_datagen.flow(x=validation_images,\n",
    "                                                 y=validation_labels,\n",
    "                                                 batch_size=32) \n",
    "  return train_generator, validation_generator\n",
    "\n",
    "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's see how a model like the one before performs in this case. Bare in mind if you do not create the model again, you will be using the one you trained for the mnist digits. Lets create it, train it, and analyse how it performed during training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, )),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=15,\n",
    "                    validation_data=validation_generator)\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation loss seem to have stagnated. This might be a clear indication that our network is not sufficient for classifying the simbols we are dealing with at the moment. We need to look for another solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
